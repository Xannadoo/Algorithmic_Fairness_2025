## Evaluate model robustness & effect of info leakage

- Estimate the robustness of Apple’s NeuralHash system.
- In 2021 Apple revealed an ML system which encoded images into hashes
- Plan was to install it on all iPhones and use to to combat child pornography
- System was claimed to be highly accurate and produced consistent hashes
- However, it was found to not be robust….play around with it on [neuralhash link](https://greentfrapp.github.io/compute-your-own-neuralhash/)
- Which tricks can spoof the system getting it to return different hashes, but where
images almost look the same?
